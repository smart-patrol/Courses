library(caret)
install.packages("ggplot2")
library(caret)
library(ggplot2)
install.packages("colorspace")
library(ggplot2)
library(caret)
data(segmentationData)
seg = segmentationData
dim(seg)
str(seg)
segmentationData$Cell <- NULL
data(segmentationData)
segmentationData$Cell <- NULL
seg = segmentationData
tables(seg$case)
table(seg$case)
dim(seg)
str(seg)
table(seg$Case)
seg$Case <- NULL
data(segmentationData)
segmentationData$Cell <- NULL
seg = segmentationData
dim(seg)
str(seg)
trainInd <- createDataPartition(seg$Case, p=.5, list=F)
trainData <- seg[trainInd, ]
dim(trainData)
prop_missing_values <- function(n, dataset)
{round(sum(is.na(dataset[,n]))/nrow(dataset),2)}
dim(trainData)
testData <- seg[-trainInd,]
dim(testData)
attach(trainData)
prop_missing_values <- function(n, dataset)
{round(sum(is.na(dataset[,n]))/nrow(dataset),2)}
dim(trainData)
sparsity <- sapply(1:ncol(trainData), FUN=prop_missing_values,
dataset= trainData)
sparsity
indx_sparse_vars = (1:length(sparsity))[sparsity >= 0.98]
clean_dataset <- function(dataset, remove_index){
cleaned_dataset <- dataset[,-remove_index]
return(cleaned_dataset)}
trainData <- clean_dataset(trainData, indx_sparse_vars)
dim(trainData)
indx_sparse_vars = (1:length(sparsity))[sparsity >= 0.98]
clean_dataset <- function(dataset, remove_index){
cleaned_dataset <- dataset[,-remove_index]
return(cleaned_dataset)}
data(segmentationData)
segmentationData$Cell <- NULL
seg = segmentationData
dim(seg)
str(seg)
head(seg,1)
trainInd <- createDataPartition(seg$Case, p=.5, list=F)
trainData <- seg[trainInd, ]
dim(trainData)
indx_sparse_vars = (1:length(sparsity))[sparsity >= 0.98]
clean_dataset <- function(dataset, remove_index){
cleaned_dataset <- dataset[,-remove_index]
return(cleaned_dataset)}
trainData2 <- clean_dataset(trainData, indx_sparse_vars)
trainData2
rm(trainData2)
nearZeroVar(trainData)
x <- read.table(text = "Product_ID     PI     t
1          0      1
1          1      1
1          1      1
1          0      2
1          1      2
1          1      2
1          1      2
1          1      2
2          0      1
2          1      1
2          0      2
2          1      2
2          0      3
2          1      3
2          1      3
2          1      3", header = TRUE)
x
find.count <- rle(x$PI)
find.count
?rle
head(mydf,20)
Threes = seq(1:12, by=3)
San = seq(1:12, by=3)
San = seq(1,12, by=3)
San = seq(1,15, by=3)
San
San = seq(3,15, by=3)
San
Jgo = seq(15,117, by=15)
Jgo
Hyaku = c(105,117, by=5 )
Hyaku
Hyaku = seq(105,117, by=5 )
Hyaku
Go = seq(105,117, by=5 )
Go
116/3
San = seq(3,15, by=3)
Jugo = seq(15,117, by=15)
Go = seq(105,117, by=5 )
Final = c(116,117)
out = as.data.frame(rbind(San, Jugo, Go, Final ))
out
rbind(San, Jugo, Go, Final ))
rbind(San, Jugo, Go, Final )
cbind(San, Jugo, Go, Final )
names(San)
rbind(San, Jugo, Go, Final )
cbind(San, Jugo, Go, Final )
?paste
paste(San , Jugo, Go, Final, sep="" )
class(San)
comb <- as.vector(San, Jugo)
comb <- as.vector(San)
comb
class(comb)
comb <- c(as.vector(San) , as.vector(Jugo))
comb
comb <- c(as.vector(San) , as.vector(Jugo), as.vector(Go), as.vector(Final))
comb
dim(comb)
class(comb)
print(comb)
comb
Jugo = seq(30,117, by=15)
Go = seq(105,117, by=5 )
Final = c(116,117)
comb <- c(as.vector(San) , as.vector(Jugo), as.vector(Go), as.vector(Final))
comb
Go = seq(110,117, by=5 )
Final = c(116,117)
comb <- c(as.vector(San) , as.vector(Jugo), as.vector(Go), as.vector(Final))
comb
comb <- c((San) , (Jugo), (Go), (Final))
comb
function zipfian {
San = seq(3,15, by=3) # counting by multiples  of 3
Jugo = seq(30,117, by=15) # counting by mutliples of 15
Go = seq(110,117, by=5 ) # counting by mutliples of 5
Final = c(116,117) # just counting
comb <- c(San , Jugo, Go, Final)
# output results
return(comb)
}
zipfian = function()  {
San = seq(3,15, by=3) # counting by multiples  of 3
Jugo = seq(30,117, by=15) # counting by mutliples of 15
Go = seq(110,117, by=5 ) # counting by mutliples of 5
Final = c(116,117) # just counting
comb <- c(San , Jugo, Go, Final)
# output results
return(comb)
}
zipfian
zipfian()
# Get data
digits.train <- read.table(url("http://www.amlbook.com/data/zip/features.train"))
digits.test <- read.table(url("http://www.amlbook.com/data/zip/features.test"))
colnames(digits.train) <- c("digit", "symmetry", "intensity")
colnames(digits.test) <- c("digit", "symmetry", "intensity")
digits.train$digit <- factor(digits.train$digit)
digits.test$digit <- factor(digits.test$digit)
library(ggplot2)
ggplot(digits.train, aes(x = symmetry, y = intensity, color = digit)) +
geom_point()
linearRegression <- function(x, y, lambda, invFn = function(x) solve(x)) {
# Calculate pseudo inverse
pseudo = invFn(t(x) %*% x + lambda * diag(ncol(x))) %*% t(x)
w = pseudo %*% y
Ein = sum(y != sign(t(w) %*% t(x)))/length(y)
# error = sum(y != sign(t(t(w) %*% t(x)))) # In case of only one record
list(w = w, Ein = Ein)
}
phi.1 <- function(x) as.matrix(cbind(bias = 1, x[,1], x[,2]))
phi.2 <- function(x) as.matrix(cbind(bias = 1, x[,1], x[, 2], x[, 1] * x[,2], x[,1]^2, x[,2]^2))
Wks = miss_val %>% select(Wkday, interval, Steps) %>%
group_by(Wkday, interval) %>%
summarize( W_steps = mean(Steps, na.rm=T))
xyplot( W_steps~ interval | Wkday, data=Wks, layout=c(1,2),
type="l",    xlab = "Interval",  ylab = "Number of steps")
library(lubridate)
library(dplyr)
library(tidyr)
library(ggplot2)
library(reshape2)
library(lattice)
library(ggvis)
library(googleVis)
Wks = miss_val %>% select(Wkday, interval, Steps) %>%
group_by(Wkday, interval) %>%
summarize( W_steps = mean(Steps, na.rm=T))
xyplot( W_steps~ interval | Wkday, data=Wks, layout=c(1,2),
type="l",    xlab = "Interval",  ylab = "Number of steps")
```{r Weeks, echo=TRUE}
miss_val$Wk = weekdays(miss_val$Date)
#table(miss_val$Wk)
miss_val$Wkday = factor(ifelse(miss_val$Wk %in% c("Saturday" , "Sunday"), "Weekend", "Weekday"))
#table(miss_val$Wk , miss_val$Wkday)
Wks = miss_val %>% select(Wkday, interval, Steps) %>%
group_by(Wkday, interval) %>%
summarize( W_steps = mean(Steps, na.rm=T))
xyplot( W_steps~ interval | Wkday, data=Wks, layout=c(1,2),
type="l",    xlab = "Interval",  ylab = "Number of steps")
newhist = miss_val %>% group_by(Date) %>%
summarize( D_steps = sum(Steps, na.rm=T))
---
title: "RR_Peer_Assignment1"
author: "Charles F."
date: "Saturday, December 13, 2014"
output: html_document
---
```{r Libraries , echo=TRUE}
library(lubridate)
library(dplyr)
library(tidyr)
library(ggplot2)
library(reshape2)
library(lattice)
library(ggvis)
library(googleVis)
```
####################################################
#Loading and preprocessing the data
##Load the data (i.e. read.csv())
```{r Readin , echo=TRUE}
getfile <- tempfile()
download.file ("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip" , getfile)
ac = read.csv(unz(getfile, "activity.csv"))
unlink(getfile)
```
##Process/transform the data (if necessary) into a format suitable for your analysis
```{r Preprocess, echo=TRUE}
str(ac) ; head(ac)
ac$Date = as.Date(ac$date)
ac$date = NULL
```
Changing date to actual date as was implied in the assignment
I could transfrom the interval as a massive factor variable but decided to leave as is for this analysis. Steps are numberic so they are fine.
##What is mean total number of steps taken per day?
```{r Meanperday, echo=TRUE}
ac_days = ac %>% group_by(Date) %>%
summarize( D_steps = sum(steps, na.rm=T))
mean(ac_days$D_steps)
```
I take the total steps for each day and then take the overall mean of the summed steps.
##Make a histogram of the total number of steps taken each day
```{r Firsthist, echo=TRUE}
ggplot(ac_days, aes(x=D_steps)) + geom_histogram(bindwidth=1 , colour="black", fill="orange" ,  position="identity") +
geom_vline(aes(xintercept=mean(D_steps, na.rm=T)),  color="black", linetype="dashed", size=1) +
geom_vline(aes(xintercept=median(D_steps, na.rm=T)),  color="blue", linetype="dashed", size=1) +
xlab("Steps Per Day") + ylab("Count") + ggtitle("Steps Histogram") +
theme_bw()
```
##Calculate and report the mean and median total number of steps taken per day
The median and mean are colored in the above histogram as well.
The mean is colored in black and the median is colored in blue
Here they are in actual hard numbers
```{r, echo=TRUE}
mean(ac_days$D_steps)
median(ac_days$D_steps)
```
It appears that the median is slightly higer than mean implying that the data is skewed, as the histogram confrims.
#What is the average daily activity pattern?
##Make a time series plot (i.e. type = "l") of the 5-minute interval (x-axis) and the average number of steps taken, averaged across all days (y-axis)
```{r Ts_int, echo=TRUE ,  results='asis'}
time = ac %>% select(interval, steps ) %>% group_by (interval) %>%
summarize( Avg_Steps = mean(steps , na.rm=T)) %>%
arrange(desc(interval))
ggplot(data=time, aes(x=interval, y=Avg_Steps , file="blue" )) +
geom_line( size=1.2) +
xlab("5 Minute Interval") + ylab("Average Steps Taken") +
ggtitle("Average Activity Pattern By Internal") +
theme_bw()
```
The above chart has the 5 Minute Interval as the horizontal axis and the Average steps per day as the vertical axis. Can't wait for Rcharts to make labeling easier.
##Which 5-minute interval, on average across all the days in the dataset, contains the maximum number of steps?
```{r Maximums, echo=TRUE}
Max_num = max(time$Avg_Steps)
Max_num
time %>% filter( Avg_Steps ==  Max_num ) %>% select(interval)
```
The interval with the higest value is at 835.
#Imputing missing values
##Calculate and report the total number of missing values in the dataset
```{r Missing, echo=TRUE}
sum(is.na(ac))
```
2304 or 13% of the data has missing values.
##Devise a strategy for filling in all of the missing values in the dataset.
##Create a new dataset that is equal to the original dataset but with the missing data filled in.
```{r Impute, echo=TRUE}
ac2 = ac %>% select(Date, interval, steps) %>%
group_by(Date, interval) %>%
summarize( D_steps = sum(steps, na.rm=T)) %>%
select(D_steps, interval, Date) %>%
rename(steps=D_steps)
miss_val = merge(ac2, time , by ="interval", sort=F )
miss_val$Steps = ifelse( miss_val$steps == 0 , miss_val$Avg_Steps, miss_val$steps)
miss_val$steps = NULL ; miss_val$Avg_Steps = NULL;
head(miss_val) ; head(ac)
sum(is.na(miss_val))
```
The dplyr takes the orginal data set and rolls it up by the Date and interval. It then calculates the sum and renames that to the orginal step name. Values are then imputed when the are equal to missing, in this case 0, with the interval average generated from the time plot.
##Make a histogram of the total number of steps taken each day and Calculate and report the mean and median total number of steps taken per day. Do these values differ from the estimates from the first part of the assignment? What is the impact of imputing missing data on the estimates of the total daily number of steps?
```{r Newhist, echo=TRUE ,  results='asis'}
newhist = miss_val %>% group_by(Date) %>%
summarize( D_steps = sum(Steps, na.rm=T))
ggvis( as.data.frame(newhist) , ~ D_steps , fill :="#FF9900") %>%
layer_histograms() %>%
add_axis("x", title="Steps", title_offset = 50) %>%
add_axis("y", title="Counts", title_offset = 50)
```
```{r Newms, echo=TRUE}
mean(newhist$D_steps, na.rm=T) ; median(newhist$D_steps, na.rm=T)
mean(ac_days$D_steps, na.rm=T) ; median(ac_days$D_steps, na.rm=T)
```
The mean drastically increased whem compared to the data set that was not imputed. There is now a drastic increase the in the overall steps per day because previous values were excluded from the totals.
There is almost a 5000 increase in the median.
###########################################################################
#Are there differences in activity patterns between weekdays and weekends?
##Create a new factor variable in the dataset with two levels - "weekday" and "weekend" indicating
```{r Weeks, echo=TRUE}
miss_val$Wk = weekdays(miss_val$Date)
#table(miss_val$Wk)
miss_val$Wkday = factor(ifelse(miss_val$Wk %in% c("Saturday" , "Sunday"), "Weekend", "Weekday"))
#table(miss_val$Wk , miss_val$Wkday)
```
Saturday and Sunday are now classfied as the Weekend. Overall, the measurements for the 7 days of tthe week - when looking at record count - appear to be even.
```{r Weeks_plot, echo=TRUE}
Wks = miss_val %>% select(Wkday, interval, Steps) %>%
group_by(Wkday, interval) %>%
summarize( W_steps = mean(Steps, na.rm=T))
xyplot( W_steps~ interval | Wkday, data=Wks, layout=c(1,2),
type="l",    xlab = "Interval",  ylab = "Number of steps")
```
Based on the above, I see that weekdays have spike in the 800 to 900 interval range.
Weekends appear to be absent of that, and what's more look like more steps are occuring overall.
---
title: "RR_Peer_Assignment1"
author: "Charles F."
date: "Saturday, December 13, 2014"
output: html_document
---
```{r Libraries , echo=TRUE}
library(lubridate)
library(dplyr)
library(tidyr)
library(ggplot2)
library(reshape2)
library(lattice)
library(ggvis)
library(googleVis)
```
####################################################
#Loading and preprocessing the data
##Load the data (i.e. read.csv())
```{r Readin , echo=TRUE}
getfile <- tempfile()
download.file ("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip" , getfile)
ac = read.csv(unz(getfile, "activity.csv"))
unlink(getfile)
```
##Process/transform the data (if necessary) into a format suitable for your analysis
```{r Preprocess, echo=TRUE}
str(ac) ; head(ac)
ac$Date = as.Date(ac$date)
ac$date = NULL
```
Changing date to actual date as was implied in the assignment
I could transfrom the interval as a massive factor variable but decided to leave as is for this analysis. Steps are numberic so they are fine.
##What is mean total number of steps taken per day?
```{r Meanperday, echo=TRUE}
ac_days = ac %>% group_by(Date) %>%
summarize( D_steps = sum(steps, na.rm=T))
mean(ac_days$D_steps)
```
I take the total steps for each day and then take the overall mean of the summed steps.
##Make a histogram of the total number of steps taken each day
```{r Firsthist, echo=TRUE}
ggplot(ac_days, aes(x=D_steps)) + geom_histogram(bindwidth=1 , colour="black", fill="orange" ,  position="identity") +
geom_vline(aes(xintercept=mean(D_steps, na.rm=T)),  color="black", linetype="dashed", size=1) +
geom_vline(aes(xintercept=median(D_steps, na.rm=T)),  color="blue", linetype="dashed", size=1) +
xlab("Steps Per Day") + ylab("Count") + ggtitle("Steps Histogram") +
theme_bw()
```
##Calculate and report the mean and median total number of steps taken per day
The median and mean are colored in the above histogram as well.
The mean is colored in black and the median is colored in blue
Here they are in actual hard numbers
```{r, echo=TRUE}
mean(ac_days$D_steps)
median(ac_days$D_steps)
```
It appears that the median is slightly higer than mean implying that the data is skewed, as the histogram confrims.
#What is the average daily activity pattern?
##Make a time series plot (i.e. type = "l") of the 5-minute interval (x-axis) and the average number of steps taken, averaged across all days (y-axis)
```{r Ts_int, echo=TRUE ,  results='asis'}
time = ac %>% select(interval, steps ) %>% group_by (interval) %>%
summarize( Avg_Steps = mean(steps , na.rm=T)) %>%
arrange(desc(interval))
ggplot(data=time, aes(x=interval, y=Avg_Steps , file="blue" )) +
geom_line( size=1.2) +
xlab("5 Minute Interval") + ylab("Average Steps Taken") +
ggtitle("Average Activity Pattern By Internal") +
theme_bw()
```
The above chart has the 5 Minute Interval as the horizontal axis and the Average steps per day as the vertical axis. Can't wait for Rcharts to make labeling easier.
##Which 5-minute interval, on average across all the days in the dataset, contains the maximum number of steps?
```{r Maximums, echo=TRUE}
Max_num = max(time$Avg_Steps)
Max_num
time %>% filter( Avg_Steps ==  Max_num ) %>% select(interval)
```
The interval with the higest value is at 835.
#Imputing missing values
##Calculate and report the total number of missing values in the dataset
```{r Missing, echo=TRUE}
sum(is.na(ac))
```
2304 or 13% of the data has missing values.
##Devise a strategy for filling in all of the missing values in the dataset.
##Create a new dataset that is equal to the original dataset but with the missing data filled in.
```{r Impute, echo=TRUE}
ac2 = ac %>% select(Date, interval, steps) %>%
group_by(Date, interval) %>%
summarize( D_steps = sum(steps, na.rm=T)) %>%
select(D_steps, interval, Date) %>%
rename(steps=D_steps)
miss_val = merge(ac2, time , by ="interval", sort=F )
miss_val$Steps = ifelse( miss_val$steps == 0 , miss_val$Avg_Steps, miss_val$steps)
miss_val$steps = NULL ; miss_val$Avg_Steps = NULL;
head(miss_val) ; head(ac)
sum(is.na(miss_val))
```
The dplyr takes the orginal data set and rolls it up by the Date and interval. It then calculates the sum and renames that to the orginal step name. Values are then imputed when the are equal to missing, in this case 0, with the interval average generated from the time plot.
##Make a histogram of the total number of steps taken each day and Calculate and report the mean and median total number of steps taken per day. Do these values differ from the estimates from the first part of the assignment? What is the impact of imputing missing data on the estimates of the total daily number of steps?
```{r Newhist, echo=TRUE ,  results='asis'}
newhist = miss_val %>% group_by(Date) %>%
summarize( D_steps = sum(Steps, na.rm=T))
ggvis( as.data.frame(newhist) , ~ D_steps , fill :="#FF9900") %>%
layer_histograms() %>%
add_axis("x", title="Steps", title_offset = 50) %>%
add_axis("y", title="Counts", title_offset = 50)
```
```{r Newms, echo=TRUE}
mean(newhist$D_steps, na.rm=T) ; median(newhist$D_steps, na.rm=T)
mean(ac_days$D_steps, na.rm=T) ; median(ac_days$D_steps, na.rm=T)
```
The mean drastically increased whem compared to the data set that was not imputed. There is now a drastic increase the in the overall steps per day because previous values were excluded from the totals.
There is almost a 5000 increase in the median.
###########################################################################
#Are there differences in activity patterns between weekdays and weekends?
##Create a new factor variable in the dataset with two levels - "weekday" and "weekend" indicating
```{r Weeks, echo=TRUE}
miss_val$Wk = weekdays(miss_val$Date)
#table(miss_val$Wk)
miss_val$Wkday = factor(ifelse(miss_val$Wk %in% c("Saturday" , "Sunday"), "Weekend", "Weekday"))
#table(miss_val$Wk , miss_val$Wkday)
```
Saturday and Sunday are now classfied as the Weekend. Overall, the measurements for the 7 days of tthe week - when looking at record count - appear to be even.
```{r Weeks_plot, echo=TRUE}
Wks = miss_val %>% select(Wkday, interval, Steps) %>%
group_by(Wkday, interval) %>%
summarize( W_steps = mean(Steps, na.rm=T))
xyplot( W_steps~ interval | Wkday, data=Wks, layout=c(1,2),
type="l",    xlab = "Interval",  ylab = "Number of steps")
```
Based on the above, I see that weekdays have spike in the 800 to 900 interval range.
Weekends appear to be absent of that, and what's more look like more steps are occuring overall.
histplot = ggvis( as.data.frame(newhist) , ~ D_steps , fill :="#FF9900") %>%
layer_histograms() %>%
add_axis("x", title="Steps", title_offset = 50) %>%
add_axis("y", title="Counts", titl
histplot
histplot = ggvis( as.data.frame(newhist) , ~ D_steps , fill :="#FF9900") %>%
layer_histograms() %>%
add_axis("x", title="Steps", title_offset = 50) %>%
add_axis("y", title="Counts", title_offset = 50)
library(lubridate)
library(dplyr)
library(tidyr)
library(ggplot2)
library(reshape2)
library(lattice)
library(ggvis)
library(googleVis)
histplot = ggvis( as.data.frame(newhist) , ~ D_steps , fill :="#FF9900") %>%
layer_histograms() %>%
add_axis("x", title="Steps", title_offset = 50) %>%
add_axis("y", title="Counts", title_offset = 50)
histplot
export_png(histplot, file = "newhist.png")
ggplot(as.data.frame(newhist) , aes(x=D_steps)) + geom_histogram(bindwidth=1 , colour="black", fill="orange" ,  position="identity") +
xlab("Steps Per Day") + ylab("Count") + ggtitle("Steps Histogram") + theme_bw()
install.packages("knitr")
library(knitr)
knit2html("C:\\Users\\Home\\Documents\\GitHub\\RepData_PeerAssessment1\\PA1_template.Rmd")
library(knitr)
knit2html("C:\\Users\\Home\\Documents\\GitHub\\RepData_PeerAssessment1\\PA1_template.Rmd")
setwd("~/GitHub/RepData_PeerAssessment1")
knit2html("C:\\Users\\Home\\Documents\\GitHub\\RepData_PeerAssessment1\\PA1_template.Rmd")
library(knitr)
knit2html("C:\\Users\\Home\\Documents\\GitHub\\RepData_PeerAssessment1\\PA1_template.Rmd")
